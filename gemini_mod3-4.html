<!DOCTYPE html>
<html lang="ja">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>バドミントン動作分析アプリ</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        /* カスタムCSS */
        body {
            font-family: 'Inter', 'Helvetica Neue', Arial, sans-serif;
        }

        /* スライダーのつまみのスタイル */
        input[type="range"]::-webkit-slider-thumb {
            -webkit-appearance: none;
            appearance: none;
            width: 20px;
            height: 20px;
            background: #fb923c; /* orange-400 */
            cursor: pointer;
            border-radius: 50%;
            border: 2px solid white;
            box-shadow: 0 0 2px rgba(0,0,0,0.3);
        }

        input[type="range"]::-moz-range-thumb {
            width: 18px; /* Firefoxはborderを内側に描画するため少し小さく */
            height: 18px;
            background: #fb923c;
            cursor: pointer;
            border-radius: 50%;
            border: 2px solid white;
            box-shadow: 0 0 2px rgba(0,0,0,0.3);
        }

        .analysis-canvas {
            border: 1px solid #e5e7eb; /* gray-200 */
            background-color: #f9fafb; /* gray-50 */
        }

        .container {
            max-width: 900px;
        }

        h1, h2, h3 {
            text-shadow: 1px 1px 2px rgba(0, 0, 0, 0.1);
        }

        /* Trimming Handle Style */
        .trimming-handle {
            cursor: grab;
        }
        .trimming-handle:active {
            cursor: grabbing;
        }
    </style>
</head>

<body class="bg-gradient-to-br from-orange-100 via-amber-100 to-yellow-100 text-gray-800 p-4 min-h-screen flex items-center justify-center">
    <div class="container mx-auto bg-white bg-opacity-70 p-6 rounded-xl shadow-2xl w-full">
        <header class="text-center mb-8">
            <h1 class="text-4xl font-bold text-orange-600">バドミントン動作分析</h1>
            <p class="text-gray-600 mt-1">動画から選手の動きを捉え、軌跡とヒートマップで可視化します。</p>
        </header>

        <!-- Section 1: Video Upload and Display -->
        <section class="mb-8 p-4 border border-orange-200 rounded-lg bg-white/50">
            <h2 class="text-2xl font-semibold mb-3 text-orange-500">1. 動画の準備</h2>
            <input type="file" id="fileInput" accept="video/*" class="block w-full text-sm text-slate-500
              file:mr-4 file:py-2 file:px-4
              file:rounded-lg file:border-0
              file:text-sm file:font-semibold
              file:bg-orange-100 file:text-orange-700
              hover:file:bg-orange-200 disabled:opacity-50 transition-colors" disabled>
            <p id="loadingTxt" class="text-sm text-gray-500 mt-2">AIモデルを読み込んでいます... 初回は数秒～数十秒かかることがあります。</p>
              
            <div class="mt-4 grid grid-cols-1 md:grid-cols-2 gap-4 items-start">
                <div>
                    <h3 class="text-lg font-medium text-gray-700 mb-1">オリジナル動画 / 範囲選択</h3>
                    <video id="video" controls class="w-full rounded-md shadow-md aspect-video hidden bg-gray-200"></video>
                </div>
                <div>
                    <h3 class="text-lg font-medium text-gray-700 mb-1">姿勢推定オーバーレイ</h3>
                    <canvas id="poseCanvas" class="w-full rounded-md shadow-md aspect-video hidden bg-gray-200"></canvas>
                    <!-- Note: poseCanvas is used for trimming interaction when isTrimmingMode is true -->
                </div>
            </div>
        </section>

        <!-- Section 2: Recording Controls -->
        <section class="mb-8 p-4 border border-orange-200 rounded-lg text-center bg-white/50">
            <h2 class="text-2xl font-semibold mb-3 text-orange-500">2. 録画と座標取得</h2>
            <button id="startButton" class="bg-orange-500 hover:bg-orange-600 text-white font-bold py-3 px-6 rounded-lg shadow-md disabled:opacity-50 transition-transform hover:scale-105" disabled>録画開始</button>
            <button id="stopButton" class="bg-red-500 hover:bg-red-600 text-white font-bold py-3 px-6 rounded-lg shadow-md disabled:opacity-50 ml-2 transition-transform hover:scale-105" disabled>録画停止</button>
            <a id="downloadLink" href="#" download="badminton_analysis.webm" class="hidden mt-4 inline-block bg-green-500 hover:bg-green-600 text-white font-bold py-3 px-6 rounded-lg shadow-md transition-transform hover:scale-105">録画をダウンロード</a>
        </section>

        <!-- Section 2.5: Court Trimming -->
        <section id="trimmingSection" class="mb-8 p-4 border border-purple-300 rounded-lg bg-white/50 hidden">
            <h2 class="text-2xl font-semibold mb-3 text-purple-600">2.5. コート範囲の調整</h2>
            <p class="text-sm text-gray-600 mb-2">動画内のバドミントンコートの四隅をビデオプレビュー上でドラッグして指定し、座標を補正します。</p>
            <div class="flex flex-col sm:flex-row gap-2 mb-4">
                <button id="startTrimmingButton" class="bg-purple-500 hover:bg-purple-600 text-white font-bold py-2 px-4 rounded-lg shadow-md transition-transform hover:scale-105 flex-1" disabled>コート範囲の調整開始</button>
                <button id="applyCorrectionButton" class="bg-teal-500 hover:bg-teal-600 text-white font-bold py-2 px-4 rounded-lg shadow-md transition-transform hover:scale-105 flex-1" disabled>座標を補正して再描画</button>
                <button id="resetTrimmingButton" class="bg-gray-400 hover:bg-gray-500 text-white font-bold py-2 px-4 rounded-lg shadow-md transition-transform hover:scale-105 flex-1" disabled>調整をリセット</button>
            </div>
            <p id="trimmingInstructions" class="text-sm text-purple-700 mb-2 h-4"></p>
            <!-- Video element is used for trimming interaction background, poseCanvas for overlay -->
        </section>

        <!-- Section 3: Movement Analysis -->
        <section id="analysisSection" class="mb-6 p-4 border border-orange-200 rounded-lg hidden bg-white/50">
            <h2 class="text-2xl font-semibold mb-3 text-orange-500">3. 移動分析結果</h2>
            <button id="analyzeButton" class="bg-blue-500 hover:bg-blue-600 text-white font-bold py-3 px-6 rounded-lg shadow-md w-full mb-4 transition-transform hover:scale-105" disabled>移動分析を開始・更新</button>

            <div id="visualizationControls" class="mt-4 hidden">
                <div class="mb-4">
                    <label for="timeSlider" class="block mb-1 text-sm font-medium text-gray-700">表示する時間範囲 (スライダーで調整):</label>
                    <input type="range" id="timeSlider" min="0" max="100" value="100" step="0.1" class="w-full h-3 bg-orange-200 rounded-lg appearance-none cursor-pointer">
                    <div class="flex justify-between text-xs text-gray-500 mt-1">
                        <span id="sliderMinTime">0.0s</span>
                        <span id="sliderCurrentTimeLabel" class="font-semibold">現在: <span id="sliderCurrentTime">0.0s</span></span>
                        <span id="sliderMaxTime">0.0s</span>
                    </div>
                </div>

                <div class="grid grid-cols-1 md:grid-cols-2 gap-6 mt-4">
                    <div>
                        <h3 class="text-xl font-semibold mb-2 text-orange-500">移動軌跡</h3>
                        <p class="text-xs text-gray-500 mb-1">青: 左足首, 赤: 右足首 (コート枠内に補正表示)</p>
                        <canvas id="trajectoryCanvas" class="w-full aspect-video analysis-canvas rounded-md shadow"></canvas>
                    </div>
                    <div>
                        <h3 class="text-xl font-semibold mb-2 text-orange-500">ヒートマップ</h3>
                        <p class="text-xs text-gray-500 mb-1">滞在頻度が高いほど赤く表示 (コート枠内に補正表示)</p>
                        <canvas id="heatmapCanvas" class="w-full aspect-video analysis-canvas rounded-md shadow"></canvas>
                    </div>
                </div>
            </div>
        </section>
    </div>

    <script type="module">
        import {
            PoseLandmarker,
            FilesetResolver,
            DrawingUtils
        } from "https://cdn.skypack.dev/@mediapipe/tasks-vision@0.10.10";

        // DOM Elements
        const fileInput = document.getElementById('fileInput');
        const video = document.getElementById('video');
        const poseCanvas = document.getElementById('poseCanvas'); // Used for pose AND trimming overlay
        const startButton = document.getElementById('startButton');
        const stopButton = document.getElementById('stopButton');
        const downloadLink = document.getElementById('downloadLink');
        const loadingTxt = document.getElementById('loadingTxt');
        const analysisSection = document.getElementById('analysisSection');
        const analyzeButton = document.getElementById('analyzeButton');
        const visualizationControls = document.getElementById('visualizationControls');
        const timeSlider = document.getElementById('timeSlider');
        const sliderMinTime = document.getElementById('sliderMinTime');
        const sliderCurrentTime = document.getElementById('sliderCurrentTime');
        const sliderMaxTime = document.getElementById('sliderMaxTime');
        const trajectoryCanvas = document.getElementById('trajectoryCanvas');
        const heatmapCanvas = document.getElementById('heatmapCanvas');

        // Trimming UI Elements
        const trimmingSection = document.getElementById('trimmingSection');
        const startTrimmingButton = document.getElementById('startTrimmingButton');
        const applyCorrectionButton = document.getElementById('applyCorrectionButton');
        const resetTrimmingButton = document.getElementById('resetTrimmingButton');
        const trimmingInstructions = document.getElementById('trimmingInstructions');

        // Canvas Contexts
        let ctxPose = poseCanvas.getContext('2d');
        let ctxTrajectory = trajectoryCanvas.getContext('2d');
        let ctxHeatmap = heatmapCanvas.getContext('2d');
          
        // MediaRecorder & PoseLandmarker
        let mediaRecorder;
        let recordedChunks = [];
        let poseLandmarker = null;
        let drawingUtilsPose = null;
        let runningMode = 'VIDEO';
        let lastVideoTime = -1;
        let anklePositions = []; 
        let originalAnklePositionsForCorrection = []; // Store raw positions for correction/reset
        let stream = null;

        const HEATMAP_GRID_SIZE = 25;
        let videoDuration = 0;

        // Trimming State Variables
        let isTrimmingMode = false;
        let cropPoints = []; // Array of 4 points: [{x,y}, {x,y}, {x,y}, {x,y}] for TL, TR, BR, BL in poseCanvas pixels
        let draggingPointIndex = -1; // Index of the cropPoint being dragged (0-3)
        const HANDLE_RADIUS = 8; // Pixel radius for drag handles on poseCanvas
        let homographyMatrix = null; // Stores the calculated perspective transform matrix

        // Target rectangle for perspective correction (normalized 0-1 coordinates for the ideal court)
        const TARGET_COURT_RECT_NORMALIZED = [
            { x: 0, y: 0 },    // Top-left
            { x: 1, y: 0 },    // Top-right
            { x: 1, y: 1 },    // Bottom-right
            { x: 0, y: 1 }     // Bottom-left
        ];

        /**
         * Initialize PoseLandmarker
         */
        async function initPoseLandmarker() {
            console.log("[DEBUG] initPoseLandmarker: Start");
            try {
                const vision = await FilesetResolver.forVisionTasks(
                    "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.10/wasm"
                );
                poseLandmarker = await PoseLandmarker.createFromOptions(vision, {
                    baseOptions: {
                        modelAssetPath: "https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task",
                        delegate: "GPU"
                    },
                    runningMode: runningMode,
                    numPoses: 1
                });
                console.log("[DEBUG] initPoseLandmarker: PoseLandmarker initialized successfully.");
                loadingTxt.textContent = "モデル読み込み完了。動画を選択してください。";
                fileInput.disabled = false;
            } catch (err) {
                console.error("[DEBUG] initPoseLandmarker: Error initializing PoseLandmarker:", err);
                loadingTxt.textContent = "モデル読み込みに失敗しました。ページをリロードしてください。";
            }
            console.log("[DEBUG] initPoseLandmarker: End");
        }
        initPoseLandmarker();

        /**
         * Handle file input change
         */
        fileInput.addEventListener('change', (event) => {
            console.log("[DEBUG] fileInput change: Event triggered.");
            const file = event.target.files[0];
            if (!file) {
                console.log("[DEBUG] fileInput change: No file selected.");
                return;
            }
            console.log("[DEBUG] fileInput change: File selected:", file.name);

            const fileURL = URL.createObjectURL(file);
            video.src = fileURL;
            video.style.display = 'block';
            poseCanvas.style.display = 'block';
            
            video.onloadedmetadata = () => {
                console.log("[DEBUG] video.onloadedmetadata: Video metadata loaded.");
                videoDuration = video.duration;
                console.log("[DEBUG] video.onloadedmetadata: Video duration:", videoDuration);
                [poseCanvas, trajectoryCanvas, heatmapCanvas].forEach(cvs => {
                    const aspectRatio = video.videoWidth / video.videoHeight;
                    const canvasWidth = cvs.parentElement.clientWidth; 
                    cvs.width = canvasWidth;
                    cvs.height = canvasWidth / aspectRatio;
                    console.log(`[DEBUG] video.onloadedmetadata: Resized canvas ${cvs.id} to ${cvs.width}x${cvs.height}`);

                    if (cvs.id === "poseCanvas") { 
                        resetCropPoints();
                        console.log("[DEBUG] video.onloadedmetadata: Crop points reset for poseCanvas.");
                    }
                });
                drawingUtilsPose = new DrawingUtils(ctxPose);
                startButton.disabled = false;
                analysisSection.classList.add('hidden');
                trimmingSection.classList.add('hidden'); 
                visualizationControls.classList.add('hidden');
                anklePositions = [];
                originalAnklePositionsForCorrection = [];
                recordedChunks = [];
                downloadLink.classList.add('hidden');
                homographyMatrix = null; 
                isTrimmingMode = false; 
                removeTrimmingEventListeners();
                loadingTxt.textContent = "動画の準備ができました。録画を開始できます。";
                console.log("[DEBUG] video.onloadedmetadata: UI reset and ready for recording.");
            };
            video.onerror = () => {
                console.error("[DEBUG] video.onerror: Error loading video file.");
                loadingTxt.textContent = "エラー: 動画ファイルの読み込みに失敗しました。";
            }
        });

        /**
         * Main drawing loop for pose estimation and trimming UI
         */
        async function predictWebcam() { 
            if (!video || video.readyState < 2) {
                requestAnimationFrame(predictWebcam);
                return;
            }
            
            ctxPose.clearRect(0, 0, poseCanvas.width, poseCanvas.height);
            if (!isTrimmingMode) { 
                 // ctxPose.drawImage(video, 0, 0, poseCanvas.width, poseCanvas.height); //This line is drawn again inside detectForVideo callback
            }

            if (isTrimmingMode) {
                ctxPose.drawImage(video, 0, 0, poseCanvas.width, poseCanvas.height); 
                drawTrimmingOverlay();
            } else if (poseLandmarker && video.currentTime !== lastVideoTime && !video.paused && !video.ended) {
                const startTimeMs = performance.now();
                lastVideoTime = video.currentTime;
                // console.log(`[DEBUG] predictWebcam: Detecting pose for time ${video.currentTime}`);

                poseLandmarker.detectForVideo(video, startTimeMs, (result) => {
                    ctxPose.clearRect(0, 0, poseCanvas.width, poseCanvas.height); 
                    ctxPose.drawImage(video, 0, 0, poseCanvas.width, poseCanvas.height);
                    if (result.landmarks && result.landmarks.length > 0) {
                        const landmarks = result.landmarks[0];
                        if (drawingUtilsPose) {
                            drawingUtilsPose.drawConnectors(landmarks, PoseLandmarker.POSE_CONNECTIONS, { color: '#FF8A65', lineWidth: 2 });
                            drawingUtilsPose.drawLandmarks(landmarks, { color: '#FFAB91', radius: 3 });
                        }
                        if (mediaRecorder && mediaRecorder.state === "recording") {
                            const leftAnkle = landmarks[27];
                            const rightAnkle = landmarks[28];
                            if (leftAnkle && rightAnkle) {
                                anklePositions.push({
                                    time: video.currentTime,
                                    leftAnkle: { x: leftAnkle.x, y: leftAnkle.y, visibility: leftAnkle.visibility },
                                    rightAnkle: { x: rightAnkle.x, y: rightAnkle.y, visibility: rightAnkle.visibility }
                                });
                            }
                        }
                    }
                });
            }
            requestAnimationFrame(predictWebcam);
        }
          
        video.addEventListener('play', () => {
            console.log("[DEBUG] video play event: Video playing.");
            lastVideoTime = -1;
            requestAnimationFrame(predictWebcam);
        });
          
        video.addEventListener('ended', () => {
            console.log("[DEBUG] video ended event: Video ended.");
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                console.log("[DEBUG] video ended event: Stopping recording.");
                stopRecording();
            }
        });

        /**
         * Start Recording
         */
        startButton.addEventListener('click', () => {
            console.log("[DEBUG] startButton click: Start recording attempt.");
            if (isTrimmingMode) {
                alert("トリミング調整モード中は録画を開始できません。調整を完了またはリセットしてください。");
                console.warn("[DEBUG] startButton click: Recording blocked, in trimming mode.");
                return;
            }
            
            if (poseCanvas.captureStream) {
                stream = poseCanvas.captureStream(30);
                 console.log("[DEBUG] startButton click: Stream captured from poseCanvas.");
            } else if (video.captureStream) { 
                 stream = video.captureStream(30);
                 console.log("[DEBUG] startButton click: Stream captured from video element.");
            } else if (video.mozCaptureStream) { 
                stream = video.mozCaptureStream(30);
                console.log("[DEBUG] startButton click: Stream captured from video element (Firefox).");
            } else {
                console.error("[DEBUG] startButton click: captureStream not supported.");
                loadingTxt.textContent = "エラー: お使いのブラウザは録画機能に対応していません。";
                return;
            }

            if (!stream) {
                 console.error("[DEBUG] startButton click: Failed to get stream.");
                 loadingTxt.textContent = "エラー: 録画ストリームの取得に失敗しました。";
                 return;
            }

            video.play(); 

            anklePositions = []; 
            originalAnklePositionsForCorrection = [];
            recordedChunks = [];
            homographyMatrix = null; 
            console.log("[DEBUG] startButton click: Recording variables reset.");

            try {
                mediaRecorder = new MediaRecorder(stream, { mimeType: 'video/webm; codecs=vp9' });
            } catch (e) {
                console.error("[DEBUG] startButton click: Error creating MediaRecorder (vp9):", e);
                try {
                    mediaRecorder = new MediaRecorder(stream, { mimeType: 'video/webm' });
                } catch (e2) {
                    console.error("[DEBUG] startButton click: Error creating MediaRecorder (default webm):", e2);
                    loadingTxt.textContent = "エラー: MediaRecorderの作成に失敗しました。録画を開始できません。";
                    return;
                }
            }
            console.log("[DEBUG] startButton click: MediaRecorder created.");

            mediaRecorder.ondataavailable = (event) => {
                if (event.data && event.data.size > 0) {
                    recordedChunks.push(event.data);
                }
            };

            mediaRecorder.onstop = () => {
                console.log("[DEBUG] mediaRecorder.onstop: Recording stopped.");
                const blob = new Blob(recordedChunks, { type: 'video/webm' });
                const url = URL.createObjectURL(blob);
                downloadLink.href = url;
                downloadLink.classList.remove('hidden');
                
                console.log("[DEBUG] mediaRecorder.onstop: Ankle positions collected during recording:", JSON.parse(JSON.stringify(anklePositions)));
                originalAnklePositionsForCorrection = JSON.parse(JSON.stringify(anklePositions)); 
                console.log("[DEBUG] mediaRecorder.onstop: Copied to originalAnklePositionsForCorrection:", JSON.parse(JSON.stringify(originalAnklePositionsForCorrection)));


                analysisSection.classList.remove('hidden');
                analyzeButton.disabled = false;
                trimmingSection.classList.remove('hidden'); 
                startTrimmingButton.disabled = false;
                resetTrimmingButton.disabled = false;
                applyCorrectionButton.disabled = true; 

                visualizationControls.classList.add('hidden'); 

                if (anklePositions.length > 0) {
                    const maxTime = anklePositions[anklePositions.length - 1].time;
                    timeSlider.max = maxTime.toFixed(1);
                    timeSlider.value = maxTime.toFixed(1);
                    sliderMaxTime.textContent = `${maxTime.toFixed(1)}s`;
                    sliderCurrentTime.textContent = `${maxTime.toFixed(1)}s`;
                } else {
                     timeSlider.max = videoDuration.toFixed(1);
                     timeSlider.value = videoDuration.toFixed(1);
                     sliderMaxTime.textContent = `${videoDuration.toFixed(1)}s`;
                     sliderCurrentTime.textContent = `${videoDuration.toFixed(1)}s`;
                }
                sliderMinTime.textContent = "0.0s";
                loadingTxt.textContent = "録画が完了しました。移動分析またはコート範囲調整を開始できます。";
                console.log("[DEBUG] mediaRecorder.onstop: UI updated for analysis/trimming.");
            };
              
            mediaRecorder.onerror = (event) => {
                console.error("[DEBUG] mediaRecorder.onerror: MediaRecorder error:", event.error);
                loadingTxt.textContent = `エラー: 録画中にエラーが発生しました: ${event.error.name}`;
                stopRecording();
            };

            mediaRecorder.start();
            console.log('[DEBUG] mediaRecorder.start: Recording started.');
            loadingTxt.textContent = "録画中です...";
            startButton.disabled = true;
            stopButton.disabled = false;
            downloadLink.classList.add('hidden');
            analyzeButton.disabled = true; 
            trimmingSection.classList.add('hidden'); 
        });

        /**
         * Stop Recording
         */
        function stopRecording() {
            console.log("[DEBUG] stopRecording: Function called.");
            if (mediaRecorder && mediaRecorder.state === 'recording') {
                mediaRecorder.stop();
                console.log('[DEBUG] stopRecording: MediaRecorder stopped.');
            }
            if (stream) {
                stream.getTracks().forEach(track => track.stop());
                stream = null; 
                console.log('[DEBUG] stopRecording: Stream tracks stopped.');
            }
            startButton.disabled = false;
            stopButton.disabled = true;
        }
        stopButton.addEventListener('click', stopRecording);

        /**
         * Analyze Button Click
         */
        analyzeButton.addEventListener('click', () => {
            console.log("[DEBUG] analyzeButton click: Analysis triggered.");
            console.log("[DEBUG] analyzeButton click: Current originalAnklePositionsForCorrection length:", originalAnklePositionsForCorrection.length);
            console.log("[DEBUG] analyzeButton click: Current anklePositions (live) length:", anklePositions.length);

            if (originalAnklePositionsForCorrection.length === 0 && anklePositions.length === 0) {
                console.warn("[DEBUG] analyzeButton click: No ankle position data to analyze.");
                loadingTxt.textContent = "情報: 分析データがありません。先に動画を録画してください。";
                return;
            }
            visualizationControls.classList.remove('hidden');
            drawAnalysis(parseFloat(timeSlider.value)); 
            loadingTxt.textContent = "移動分析結果を表示しています。";
            console.log("[DEBUG] analyzeButton click: Analysis display updated.");
        });

        /**
         * Time Slider Input Change
         */
        timeSlider.addEventListener('input', () => {
            const currentTime = parseFloat(timeSlider.value);
            // console.log(`[DEBUG] timeSlider input: Slider changed to ${currentTime}s.`);
            sliderCurrentTime.textContent = `${currentTime.toFixed(1)}s`;
            if (!visualizationControls.classList.contains('hidden')) { 
                 drawAnalysis(currentTime);
            }
        });
          
        /**
         * Draw Analysis (Trajectory and Heatmap)
         * Uses originalAnklePositionsForCorrection and applies homography if matrix exists
         */
        function drawAnalysis(currentTime) {
            console.log(`[DEBUG] drawAnalysis: Drawing analysis for time: ${currentTime}`);
            ctxTrajectory.clearRect(0, 0, trajectoryCanvas.width, trajectoryCanvas.height);
            ctxHeatmap.clearRect(0, 0, heatmapCanvas.width, heatmapCanvas.height);

            ctxTrajectory.strokeStyle = '#888'; 
            ctxTrajectory.lineWidth = 2;
            ctxTrajectory.strokeRect(0, 0, trajectoryCanvas.width, trajectoryCanvas.height);
            
            let positionsToAnalyze;
            const basePositions = originalAnklePositionsForCorrection.length > 0 ? originalAnklePositionsForCorrection : anklePositions;
            console.log("[DEBUG] drawAnalysis: Using basePositions length:", basePositions.length, originalAnklePositionsForCorrection.length > 0 ? "(from originalAnklePositionsForCorrection)" : "(from live anklePositions)");

            if (homographyMatrix && cropPoints.length === 4) {
                console.log("[DEBUG] drawAnalysis: Applying homography correction. Matrix:", homographyMatrix);
                positionsToAnalyze = correctAnklePositions([...basePositions], homographyMatrix, poseCanvas.width, poseCanvas.height);
            } else {
                console.log("[DEBUG] drawAnalysis: No homography matrix or crop points not set. Using base positions directly.");
                positionsToAnalyze = [...basePositions]; 
            }
            console.log("[DEBUG] drawAnalysis: positionsToAnalyze (after potential correction) length:", positionsToAnalyze.length);
            if(positionsToAnalyze.length > 0) console.log("[DEBUG] drawAnalysis: Sample position to analyze [0]:", JSON.parse(JSON.stringify(positionsToAnalyze[0])));
            
            const filteredPositions = positionsToAnalyze.filter(p => p.time <= currentTime);
            console.log(`[DEBUG] drawAnalysis: Filtered positions for time <= ${currentTime}, count: ${filteredPositions.length}`);
            
            if (filteredPositions.length === 0) {
                console.warn("[DEBUG] drawAnalysis: No positions found for the selected time range.");
                const noDataMsg = "この時間範囲に表示できるデータがありません。";
                [ctxTrajectory, ctxHeatmap].forEach(ctx => {
                    ctx.font = "16px Arial"; 
                    ctx.fillStyle = "gray";
                    ctx.textAlign = "center";
                    const canvas = ctx.canvas;
                    const words = noDataMsg.split('');
                    let line = '';
                    let y = canvas.height / 2 - 10;
                    for(let n = 0; n < words.length; n++) {
                        let testLine = line + words[n];
                        let metrics = ctx.measureText(testLine);
                        let testWidth = metrics.width;
                        if (testWidth > canvas.width * 0.9 && n > 0) {
                            ctx.fillText(line, canvas.width / 2, y);
                            line = words[n];
                            y += 20; 
                        } else {
                            line = testLine;
                        }
                    }
                    ctx.fillText(line, canvas.width/2, y);
                });
                loadingTxt.textContent = "情報: 選択した時間範囲に座標データがありません。";
                return;
            } else {
                 loadingTxt.textContent = "移動分析結果を表示中...";
            }
            
            console.log("[DEBUG] drawAnalysis: Calling drawTrajectory.");
            drawTrajectory(filteredPositions, trajectoryCanvas, ctxTrajectory);
            console.log("[DEBUG] drawAnalysis: Calling drawHeatmap.");
            drawHeatmap(filteredPositions, heatmapCanvas, ctxHeatmap);
            console.log("[DEBUG] drawAnalysis: Finished drawing analysis visualizations.");
        }

        /**
         * Draw Trajectory on a given canvas
         */
        function drawTrajectory(positions, canvas, ctx) {
            console.log(`[DEBUG] drawTrajectory: Drawing trajectory with ${positions.length} positions.`);
            ctx.lineWidth = 2;
            const drawSingleTrajectory = (ankleKey, color) => {
                console.log(`[DEBUG] drawTrajectory: Drawing for ${ankleKey} with color ${color}`);
                ctx.strokeStyle = color;
                ctx.beginPath();
                let firstPoint = true;
                for (const pos of positions) {
                    const ankle = pos[ankleKey];
                    if (ankle && typeof ankle.x === 'number' && typeof ankle.y === 'number') { 
                        const x = ankle.x * canvas.width;
                        const y = ankle.y * canvas.height;
                        if (firstPoint) {
                            ctx.moveTo(x, y);
                            firstPoint = false;
                        } else {
                            ctx.lineTo(x, y);
                        }
                    } else {
                        // console.warn(`[DEBUG] drawTrajectory: Invalid or missing ${ankleKey} data for a point.`, ankle);
                        firstPoint = true; 
                    }
                }
                ctx.stroke();
            };
            drawSingleTrajectory('leftAnkle', 'rgba(59, 130, 246, 0.8)'); // Blue
            drawSingleTrajectory('rightAnkle', 'rgba(239, 68, 68, 0.8)'); // Red
            console.log("[DEBUG] drawTrajectory: Trajectory drawing complete.");
        }

        /**
         * Draw Heatmap on a given canvas
         */
        function drawHeatmap(positions, canvas, ctx) {
            console.log(`[DEBUG] drawHeatmap: Drawing heatmap with ${positions.length} positions.`);
            const gridW = canvas.width / HEATMAP_GRID_SIZE;
            const gridH = canvas.height / HEATMAP_GRID_SIZE;
            const heatmapData = Array(HEATMAP_GRID_SIZE).fill(null).map(() => Array(HEATMAP_GRID_SIZE).fill(0));
            let maxHits = 0;

            const processAnkle = (ankle) => {
                if (ankle && typeof ankle.x === 'number' && typeof ankle.y === 'number') {
                    const gridX = Math.min(HEATMAP_GRID_SIZE - 1, Math.max(0, Math.floor(ankle.x * HEATMAP_GRID_SIZE)));
                    const gridY = Math.min(HEATMAP_GRID_SIZE - 1, Math.max(0, Math.floor(ankle.y * HEATMAP_GRID_SIZE)));
                    heatmapData[gridY][gridX]++;
                    if (heatmapData[gridY][gridX] > maxHits) maxHits = heatmapData[gridY][gridX];
                } else {
                    // console.warn("[DEBUG] drawHeatmap: Invalid or missing ankle data for heatmap processing.", ankle);
                }
            };

            for (const pos of positions) {
                processAnkle(pos.leftAnkle);
                processAnkle(pos.rightAnkle);
            }
            console.log(`[DEBUG] drawHeatmap: Max hits in a grid cell: ${maxHits}`);

            if (maxHits === 0) {
                console.log("[DEBUG] drawHeatmap: No hits, skipping heatmap drawing.");
                return;
            }

            for (let y = 0; y < HEATMAP_GRID_SIZE; y++) {
                for (let x = 0; x < HEATMAP_GRID_SIZE; x++) {
                    if (heatmapData[y][x] > 0) {
                        const intensity = heatmapData[y][x] / maxHits;
                        const r = Math.floor(255 * Math.min(1, intensity * 1.5)); 
                        const g = Math.floor(255 * Math.max(0, (1 - intensity * 1.5))); 
                        const b = 0; 
                        ctx.fillStyle = `rgba(${r}, ${g}, ${b}, ${Math.max(0.1, intensity * 0.8)})`; 
                        ctx.fillRect(x * gridW, y * gridH, gridW, gridH);
                    }
                }
            }
            console.log("[DEBUG] drawHeatmap: Heatmap drawing complete.");
        }

        // --- Trimming and Correction Logic ---

        function resetCropPoints() {
            cropPoints = [
                { x: 0, y: 0 },                                      
                { x: poseCanvas.width, y: 0 },                       
                { x: poseCanvas.width, y: poseCanvas.height },      
                { x: 0, y: poseCanvas.height }                       
            ];
            console.log("[DEBUG] resetCropPoints: Crop points reset to canvas defaults:", JSON.parse(JSON.stringify(cropPoints)));
        }
        
        startTrimmingButton.addEventListener('click', () => {
            console.log("[DEBUG] startTrimmingButton click: Entering trimming mode.");
            isTrimmingMode = true;
            video.pause(); 
            trimmingInstructions.textContent = "コートの四隅をドラッグして調整後、「座標を補正」を押します。";
            startTrimmingButton.disabled = true;
            applyCorrectionButton.disabled = false;
            resetTrimmingButton.disabled = false;
            analyzeButton.disabled = true; 
            fileInput.disabled = true; 
            startButton.disabled = true; 

            if (cropPoints.length !== 4) { 
                resetCropPoints();
            }
            addTrimmingEventListeners();
            requestAnimationFrame(predictWebcam); 
            console.log("[DEBUG] startTrimmingButton click: Trimming mode setup complete.");
        });

        applyCorrectionButton.addEventListener('click', () => {
            console.log("[DEBUG] applyCorrectionButton click: Attempting to apply correction.");
            if (cropPoints.length !== 4) {
                trimmingInstructions.textContent = "エラー: 4つの角が定義されていません。";
                console.error("[DEBUG] applyCorrectionButton click: Crop points not defined.");
                return;
            }
            isTrimmingMode = false;
            removeTrimmingEventListeners();
            console.log("[DEBUG] applyCorrectionButton click: Exited trimming mode.");
            
            homographyMatrix = computeHomographyMatrix(cropPoints, TARGET_COURT_RECT_NORMALIZED);
            console.log("[DEBUG] applyCorrectionButton click: Computed homographyMatrix:", homographyMatrix);
            
            trimmingInstructions.textContent = "座標補正を適用しました。分析を更新してください。";
            startTrimmingButton.disabled = false;
            applyCorrectionButton.disabled = true;
            analyzeButton.disabled = false; 
            fileInput.disabled = false;

            if (!visualizationControls.classList.contains('hidden')) {
                 console.log("[DEBUG] applyCorrectionButton click: Redrawing analysis with new correction.");
                 drawAnalysis(parseFloat(timeSlider.value));
            }
            requestAnimationFrame(predictWebcam); 
        });

        resetTrimmingButton.addEventListener('click', () => {
            console.log("[DEBUG] resetTrimmingButton click: Resetting trimming.");
            isTrimmingMode = false;
            removeTrimmingEventListeners();
            homographyMatrix = null; 
            resetCropPoints(); 
            
            trimmingInstructions.textContent = "トリミング調整をリセットしました。";
            startTrimmingButton.disabled = false;
            applyCorrectionButton.disabled = true;
            analyzeButton.disabled = false;
            fileInput.disabled = false;

            if (!visualizationControls.classList.contains('hidden')) {
                 console.log("[DEBUG] resetTrimmingButton click: Redrawing analysis with original data.");
                 drawAnalysis(parseFloat(timeSlider.value));
            }
            requestAnimationFrame(predictWebcam); 
             console.log("[DEBUG] resetTrimmingButton click: Trimming reset complete.");
        });

        function addTrimmingEventListeners() {
            poseCanvas.addEventListener('mousedown', handleMouseDownTrimming);
            poseCanvas.addEventListener('mousemove', handleMouseMoveTrimming);
            poseCanvas.addEventListener('mouseup', handleMouseUpTrimming);
            poseCanvas.addEventListener('mouseleave', handleMouseUpTrimming); 
            console.log("[DEBUG] addTrimmingEventListeners: Trimming event listeners added.");
        }

        function removeTrimmingEventListeners() {
            poseCanvas.removeEventListener('mousedown', handleMouseDownTrimming);
            poseCanvas.removeEventListener('mousemove', handleMouseMoveTrimming);
            poseCanvas.removeEventListener('mouseup', handleMouseUpTrimming);
            poseCanvas.removeEventListener('mouseleave', handleMouseUpTrimming);
            console.log("[DEBUG] removeTrimmingEventListeners: Trimming event listeners removed.");
        }
        
        function drawTrimmingOverlay() {
            if (cropPoints.length !== 4) return;
            // console.log("[DEBUG] drawTrimmingOverlay: Drawing trimming UI.");

            ctxPose.fillStyle = "rgba(0, 0, 0, 0.3)";
            ctxPose.fillRect(0, 0, poseCanvas.width, poseCanvas.height);

            ctxPose.save();
            ctxPose.beginPath();
            ctxPose.moveTo(cropPoints[0].x, cropPoints[0].y);
            for (let i = 1; i < 4; i++) {
                ctxPose.lineTo(cropPoints[i].x, cropPoints[i].y);
            }
            ctxPose.closePath();
            
            ctxPose.globalCompositeOperation = 'destination-out';
            ctxPose.fillStyle = "black"; 
            ctxPose.fill();
            ctxPose.restore(); 

            ctxPose.strokeStyle = 'rgba(255, 0, 0, 0.9)'; 
            ctxPose.lineWidth = 2;
            ctxPose.beginPath();
            ctxPose.moveTo(cropPoints[0].x, cropPoints[0].y);
            for (let i = 1; i < 4; i++) {
                ctxPose.lineTo(cropPoints[i].x, cropPoints[i].y);
            }
            ctxPose.closePath();
            ctxPose.stroke();

            ctxPose.fillStyle = 'rgba(255, 0, 0, 0.9)';
            for (let i = 0; i < 4; i++) {
                ctxPose.beginPath();
                ctxPose.arc(cropPoints[i].x, cropPoints[i].y, HANDLE_RADIUS, 0, 2 * Math.PI);
                ctxPose.fill();
            }
        }

        function getMousePos(canvas, evt) {
            const rect = canvas.getBoundingClientRect();
            return {
                x: evt.clientX - rect.left,
                y: evt.clientY - rect.top
            };
        }

        function handleMouseDownTrimming(event) {
            if (!isTrimmingMode) return;
            const mousePos = getMousePos(poseCanvas, event);
            for (let i = 0; i < cropPoints.length; i++) {
                const dx = mousePos.x - cropPoints[i].x;
                const dy = mousePos.y - cropPoints[i].y;
                if (dx * dx + dy * dy < HANDLE_RADIUS * HANDLE_RADIUS) {
                    draggingPointIndex = i;
                    poseCanvas.classList.add('trimming-handle');
                    // console.log(`[DEBUG] handleMouseDownTrimming: Started dragging point ${i}`);
                    return;
                }
            }
        }

        function handleMouseMoveTrimming(event) {
            if (!isTrimmingMode || draggingPointIndex === -1) return;
            const mousePos = getMousePos(poseCanvas, event);
            cropPoints[draggingPointIndex].x = Math.max(0, Math.min(poseCanvas.width, mousePos.x));
            cropPoints[draggingPointIndex].y = Math.max(0, Math.min(poseCanvas.height, mousePos.y));
            // console.log(`[DEBUG] handleMouseMoveTrimming: Dragging point ${draggingPointIndex} to`, cropPoints[draggingPointIndex]);
        }

        function handleMouseUpTrimming() {
            if (!isTrimmingMode) return;
            // console.log(`[DEBUG] handleMouseUpTrimming: Stopped dragging point ${draggingPointIndex}`);
            draggingPointIndex = -1;
            poseCanvas.classList.remove('trimming-handle');
        }

        /**
         * Computes the homography matrix.
         */
        function computeHomographyMatrix(srcPts, dstPtsNorm) {
            console.log("[DEBUG] computeHomographyMatrix: Function called.");
            if (srcPts.length !== 4 || dstPtsNorm.length !== 4) {
                console.error("[DEBUG] computeHomographyMatrix: Requires 4 source and 4 destination points.");
                return null;
            }
            // This is a placeholder - true homography is complex.
            console.warn("[DEBUG] computeHomographyMatrix: This is a placeholder and does NOT compute a true perspective transform.");
            console.log("[DEBUG] computeHomographyMatrix: Source Points (Pixels on poseCanvas):", JSON.parse(JSON.stringify(srcPts)));
            console.log("[DEBUG] computeHomographyMatrix: Destination Points (Normalized 0-1 for target court):", JSON.parse(JSON.stringify(dstPtsNorm)));
            
            // Placeholder returns an identity matrix.
            const identityMatrix = [
                1, 0, 0, 
                0, 1, 0, 
                0, 0, 1  
            ];
            console.log("[DEBUG] computeHomographyMatrix: Returning placeholder (identity) matrix:", identityMatrix);
            return identityMatrix;
        }

        /**
         * Applies homography transformation to a point.
         */
        function applyHomography(pointNormSrc, H, srcCanvasWidth, srcCanvasHeight) {
            // console.log("[DEBUG] applyHomography: Called with pointNormSrc:", pointNormSrc, "H:", H, `srcSize: ${srcCanvasWidth}x${srcCanvasHeight}`);
            if (!H || H.length !== 9) {
                // console.warn("[DEBUG] applyHomography: Invalid or no homography matrix. Returning original point.");
                return pointNormSrc;
            }

            const srcXpx = pointNormSrc.x * srcCanvasWidth;
            const srcYpx = pointNormSrc.y * srcCanvasHeight;

            const denominator = H[6] * srcXpx + H[7] * srcYpx + H[8]; 

            if (Math.abs(denominator) < 1e-7) { 
                console.warn("[DEBUG] applyHomography: Denominator is close to zero. Returning original normalized point to avoid division issues.");
                return pointNormSrc; 
            }

            const dstNormX = (H[0] * srcXpx + H[1] * srcYpx + H[2]) / denominator;
            const dstNormY = (H[3] * srcXpx + H[4] * srcYpx + H[5]) / denominator;
            // console.log(`[DEBUG] applyHomography: Transformed point from (${pointNormSrc.x.toFixed(3)}, ${pointNormSrc.y.toFixed(3)}) to (${dstNormX.toFixed(3)}, ${dstNormY.toFixed(3)})`);
            
            return { x: dstNormX, y: dstNormY };
        }
        
        /**
         * Corrects all ankle positions using the homography matrix.
         */
        function correctAnklePositions(positions, H, sourceWidth, sourceHeight) {
            console.log(`[DEBUG] correctAnklePositions: Correcting ${positions.length} positions with H:`, H);
            if (!H) {
                console.warn("[DEBUG] correctAnklePositions: No homography matrix provided. Returning original positions.");
                return positions;
            }
            
            const corrected = positions.map(p => {
                const correctedP = { ...p }; 
                if (p.leftAnkle) {
                    const originalLeft = {...p.leftAnkle};
                    correctedP.leftAnkle = { 
                        ...p.leftAnkle, 
                        ...applyHomography(p.leftAnkle, H, sourceWidth, sourceHeight) 
                    };
                    // if (p.time < 0.5) console.log(`[DEBUG] correctAnklePositions (Left Sample): Time ${p.time.toFixed(2)} Original: (${originalLeft.x.toFixed(3)},${originalLeft.y.toFixed(3)}) -> Corrected: (${correctedP.leftAnkle.x.toFixed(3)},${correctedP.leftAnkle.y.toFixed(3)})`);
                }
                if (p.rightAnkle) {
                     const originalRight = {...p.rightAnkle};
                    correctedP.rightAnkle = { 
                        ...p.rightAnkle, 
                        ...applyHomography(p.rightAnkle, H, sourceWidth, sourceHeight) 
                    };
                    // if (p.time < 0.5) console.log(`[DEBUG] correctAnklePositions (Right Sample): Time ${p.time.toFixed(2)} Original: (${originalRight.x.toFixed(3)},${originalRight.y.toFixed(3)}) -> Corrected: (${correctedP.rightAnkle.x.toFixed(3)},${correctedP.rightAnkle.y.toFixed(3)})`);
                }
                return correctedP;
            });
            console.log("[DEBUG] correctAnklePositions: Correction complete for all positions.");
            if(corrected.length > 0) console.log("[DEBUG] correctAnklePositions: Sample corrected position [0]:", JSON.parse(JSON.stringify(corrected[0])));
            return corrected;
        }

    </script>
</body>
</html>
